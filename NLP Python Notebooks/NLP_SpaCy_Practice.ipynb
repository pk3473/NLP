{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"Alice follows a large white rabbit down a \"Rabbit-hole\". She finds a tiny door. When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door. She then eats something labeled \"Eat me\" and grows larger. She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her. She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size. In order to get out, she has to use the \"magic fan.\"\n",
    "She enters a kitchen, in which there is a cook and a woman holding a baby. She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around. The baby then turns into a pig and squirms out of her grip. \"The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\" After a while, she leaves.\n",
    "The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit. When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\". Alice \"boxes the ears\", then flees when all the playing cards come for her. Then she wakes up and realizes it was all a dream.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice follows a large white rabbit down a \"Rabbit-hole\". She finds a tiny door. When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door. She then eats something labeled \"Eat me\" and grows larger. She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her. She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size. In order to get out, she has to use the \"magic fan.\"\n",
       "She enters a kitchen, in which there is a cook and a woman holding a baby. She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around. The baby then turns into a pig and squirms out of her grip. \"The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\" After a while, she leaves.\n",
       "The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit. When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\". Alice \"boxes the ears\", then flees when all the playing cards come for her. Then she wakes up and realizes it was all a dream."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_doc = nlp(doc)\n",
    "spacy_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice follows a large white rabbit down a \"Rabbit-hole\". She finds a tiny door. When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door. She then eats something labeled \"Eat me\" and grows larger. She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her. She enters the \"White Rabbit\\'s tiny House,\" but suddenly resumes her normal size. In order to get out, she has to use the \"magic fan.\"\\nShe enters a kitchen, in which there is a cook and a woman holding a baby. She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around. The baby then turns into a pig and squirms out of her grip. \"The Duchess\\'s Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter\\'s \"Mad Tea-Party.\" After a while, she leaves.\\nThe Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit. When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\". Alice \"boxes the ears\", then flees when all the playing cards come for her. Then she wakes up and realizes it was all a dream.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice, follows, a, large, white, rabbit, down, a, \", Rabbit, -, hole, \", ., She, finds, a, tiny, door, ., When, she, finds, a, bottle, labeled, \", Drink, me, \", ,, she, does, ,, and, shrinks, ,, but, not, enough, to, pass, through, the, door, ., She, then, eats, something, labeled, \", Eat, me, \", and, grows, larger, ., She, finds, a, fan, when, enables, her, to, shrink, enough, to, get, into, the, \", Garden, \", and, try, to, get, a, \", Dog, \", to, play, with, her, ., She, enters, the, \", White, Rabbit, 's, tiny, House, ,, \", but, suddenly, resumes, her, normal, size, ., In, order, to, get, out, ,, she, has, to, use, the, \", magic, fan, ., \", \n",
      ", She, enters, a, kitchen, ,, in, which, there, is, a, cook, and, a, woman, holding, a, baby, ., She, persuades, the, woman, to, give, her, the, child, and, takes, the, infant, outside, after, the, cook, starts, throwing, things, around, ., The, baby, then, turns, into, a, pig, and, squirms, out, of, her, grip, ., \", The, Duchess, 's, Cheshire, Cat, \", appears, and, disappears, a, couple, of, times, to, Alice, and, directs, her, to, the, Mad, Hatter, 's, \", Mad, Tea, -, Party, ., \", After, a, while, ,, she, leaves, ., \n",
      ", The, Queen, invites, Alice, to, join, the, \", ROYAL, PROCESSION, \", :, a, parade, of, marching, playing, cards, and, others, headed, by, the, White, Rabbit, ., When, Alice, \", unintentionally, offends, the, Queen, \", ,, the, latter, summons, the, \", Executioner, \", ., Alice, \", boxes, the, ears, \", ,, then, flees, when, all, the, playing, cards, come, for, her, ., Then, she, wakes, up, and, realizes, it, was, all, a, dream, .]\n"
     ]
    }
   ],
   "source": [
    "tokens = list(spacy_doc)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Alice follows a large white rabbit down a \"Rabbit-hole\".\n",
      "1 She finds a tiny door.\n",
      "2 When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door.\n",
      "3 She then eats something labeled \"Eat me\" and grows larger.\n",
      "4 She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her.\n",
      "5 She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size.\n",
      "6 In order to get out, she has to use the \"magic fan.\n",
      "7 \"\n",
      "\n",
      "8 She enters a kitchen, in which there is a cook and a woman holding a baby.\n",
      "9 She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around.\n",
      "10 The baby then turns into a pig and squirms out of her grip.\n",
      "11 \"\n",
      "12 The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\n",
      "13 \"\n",
      "14 After a while, she leaves.\n",
      "\n",
      "15 The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit.\n",
      "16 When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\".\n",
      "17 Alice \"boxes the ears\", then flees when all the playing cards come for her.\n",
      "18 Then she wakes up and realizes it was all a dream.\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(spacy_doc.sents):\n",
    "    print(index,sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_extension',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'string',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are many properties for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_extension', 'has_vector', 'head', 'i', 'idx', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'shape', 'shape_', 'similarity', 'string', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n"
     ]
    }
   ],
   "source": [
    "first_word = tokens[0]\n",
    "print (dir(first_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_bracket:  False\n",
      "like_num:  False\n",
      "right_edge:  Alice\n",
      "sentiment:  0.0\n",
      "dep_:  nsubj\n"
     ]
    }
   ],
   "source": [
    "print (\"is_bracket: \", first_word.is_bracket)\n",
    "print (\"like_num: \", first_word.like_num)\n",
    "print (\"right_edge: \", first_word.right_edge)\n",
    "print (\"sentiment: \", first_word.sentiment)\n",
    "print (\"dep_: \", first_word.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.955463\n"
     ]
    }
   ],
   "source": [
    " print(first_word.vector_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these properties, we can infact clean the text data. For example, following code cell shows how to remove the tokens which are punctuations and stopwords, and lemmatize the remaining ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of punctuations\n",
    "\n",
    "property: is_punct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for t in tokens if (t.is_punct == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice, follows, a, large, white, rabbit, down, a, Rabbit, hole, She, finds, a, tiny, door, When, she, finds, a, bottle, labeled, Drink, me, she, does, and, shrinks, but, not, enough, to, pass, through, the, door, She, then, eats, something, labeled, Eat, me, and, grows, larger, She, finds, a, fan, when, enables, her, to, shrink, enough, to, get, into, the, Garden, and, try, to, get, a, Dog, to, play, with, her, She, enters, the, White, Rabbit, 's, tiny, House, but, suddenly, resumes, her, normal, size, In, order, to, get, out, she, has, to, use, the, magic, fan, \n",
      ", She, enters, a, kitchen, in, which, there, is, a, cook, and, a, woman, holding, a, baby, She, persuades, the, woman, to, give, her, the, child, and, takes, the, infant, outside, after, the, cook, starts, throwing, things, around, The, baby, then, turns, into, a, pig, and, squirms, out, of, her, grip, The, Duchess, 's, Cheshire, Cat, appears, and, disappears, a, couple, of, times, to, Alice, and, directs, her, to, the, Mad, Hatter, 's, Mad, Tea, Party, After, a, while, she, leaves, \n",
      ", The, Queen, invites, Alice, to, join, the, ROYAL, PROCESSION, a, parade, of, marching, playing, cards, and, others, headed, by, the, White, Rabbit, When, Alice, unintentionally, offends, the, Queen, the, latter, summons, the, Executioner, Alice, boxes, the, ears, then, flees, when, all, the, playing, cards, come, for, her, Then, she, wakes, up, and, realizes, it, was, all, a, dream]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of Stopwords\n",
    "\n",
    "property: is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice, follows, large, white, rabbit, Rabbit, hole, finds, tiny, door, finds, bottle, labeled, Drink, shrinks, pass, door, eats, labeled, Eat, grows, larger, finds, fan, enables, shrink, Garden, try, Dog, play, enters, White, Rabbit, tiny, House, suddenly, resumes, normal, size, order, use, magic, fan, \n",
      ", enters, kitchen, cook, woman, holding, baby, persuades, woman, child, takes, infant, outside, cook, starts, throwing, things, baby, turns, pig, squirms, grip, Duchess, Cheshire, Cat, appears, disappears, couple, times, Alice, directs, Mad, Hatter, Mad, Tea, Party, leaves, \n",
      ", Queen, invites, Alice, join, ROYAL, PROCESSION, parade, marching, playing, cards, headed, White, Rabbit, Alice, unintentionally, offends, Queen, summons, Executioner, Alice, boxes, ears, flees, playing, cards, come, wakes, realizes, dream]\n"
     ]
    }
   ],
   "source": [
    "tokens = [t for t in tokens if (t.is_stop == False)]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Property: lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'follow', 'large', 'white', 'rabbit', 'rabbit', 'hole', 'find', 'tiny', 'door', 'find', 'bottle', 'label', 'drink', 'shrink', 'pass', 'door', 'eat', 'label', 'eat', 'grow', 'large', 'find', 'fan', 'enable', 'shrink', 'Garden', 'try', 'Dog', 'play', 'enter', 'White', 'Rabbit', 'tiny', 'House', 'suddenly', 'resume', 'normal', 'size', 'order', 'use', 'magic', 'fan', '\\n', 'enter', 'kitchen', 'cook', 'woman', 'hold', 'baby', 'persuade', 'woman', 'child', 'take', 'infant', 'outside', 'cook', 'start', 'throw', 'thing', 'baby', 'turn', 'pig', 'squirm', 'grip', 'Duchess', 'Cheshire', 'Cat', 'appear', 'disappear', 'couple', 'time', 'Alice', 'direct', 'Mad', 'Hatter', 'mad', 'Tea', 'Party', 'leave', '\\n', 'Queen', 'invite', 'Alice', 'join', 'ROYAL', 'procession', 'parade', 'march', 'playing', 'card', 'head', 'White', 'Rabbit', 'Alice', 'unintentionally', 'offend', 'queen', 'summon', 'Executioner', 'Alice', 'box', 'ear', 'flee', 'playing', 'card', 'come', 'wake', 'realize', 'dream']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_words = [token.lemma_ for token in tokens]\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we join these lemmatized words to produce a cleaned document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice follow large white rabbit rabbit hole find tiny door find bottle label drink shrink pass door eat label eat grow large find fan enable shrink Garden try Dog play enter White Rabbit tiny House suddenly resume normal size order use magic fan \n",
      " enter kitchen cook woman hold baby persuade woman child take infant outside cook start throw thing baby turn pig squirm grip Duchess Cheshire Cat appear disappear couple time Alice direct Mad Hatter mad Tea Party leave \n",
      " Queen invite Alice join ROYAL procession parade march playing card head White Rabbit Alice unintentionally offend queen summon Executioner Alice box ear flee playing card come wake realize dream\n"
     ]
    }
   ],
   "source": [
    "cleaned_doc = \" \".join(lemmatized_words)\n",
    "print(cleaned_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Property: token.dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator at 0x26d2c58ae08>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_doc.sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Alice follows a large white rabbit down a \"Rabbit-hole\".\n",
      "1 She finds a tiny door.\n",
      "2 When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door.\n",
      "3 She then eats something labeled \"Eat me\" and grows larger.\n",
      "4 She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her.\n",
      "5 She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size.\n",
      "6 In order to get out, she has to use the \"magic fan.\n",
      "7 \"\n",
      "\n",
      "8 She enters a kitchen, in which there is a cook and a woman holding a baby.\n",
      "9 She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around.\n",
      "10 The baby then turns into a pig and squirms out of her grip.\n",
      "11 \"\n",
      "12 The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\n",
      "13 \"\n",
      "14 After a while, she leaves.\n",
      "\n",
      "15 The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit.\n",
      "16 When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\".\n",
      "17 Alice \"boxes the ears\", then flees when all the playing cards come for her.\n",
      "18 Then she wakes up and realizes it was all a dream.\n"
     ]
    }
   ],
   "source": [
    "for index,sentence in enumerate(spacy_doc.sents):\n",
    "    print(index, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Alice ( nsubj )\n",
      "Token: follows ( ROOT )\n",
      "Token: a ( det )\n",
      "Token: large ( amod )\n",
      "Token: white ( amod )\n",
      "Token: rabbit ( dobj )\n",
      "Token: down ( prep )\n",
      "Token: a ( det )\n",
      "Token: \" ( punct )\n",
      "Token: Rabbit ( compound )\n",
      "Token: - ( punct )\n",
      "Token: hole ( pobj )\n",
      "Token: \" ( punct )\n",
      "Token: . ( punct )\n"
     ]
    }
   ],
   "source": [
    "for token in list(spacy_doc.sents)[0]:\n",
    "    print(\"Token:\", token.text, \"(\",token.dep_,\")\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the grammar tree as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0\" class=\"displacy\" width=\"1550\" height=\"512.0\" direction=\"ltr\" style=\"max-width: none; height: 512.0px; color: white; background: #09a3d5; font-family: Trebuchet MS; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Alice</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">follows</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">large</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">white</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">rabbit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">down</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a &quot;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">Rabbit-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">hole&quot;.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-0\" stroke-width=\"2px\" d=\"M62,377.0 62,352.0 188.0,352.0 188.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,379.0 L58,371.0 66,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-1\" stroke-width=\"2px\" d=\"M362,377.0 362,302.0 794.0,302.0 794.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,379.0 L358,371.0 366,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-2\" stroke-width=\"2px\" d=\"M512,377.0 512,327.0 791.0,327.0 791.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,379.0 L508,371.0 516,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-3\" stroke-width=\"2px\" d=\"M662,377.0 662,352.0 788.0,352.0 788.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M662,379.0 L658,371.0 666,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-4\" stroke-width=\"2px\" d=\"M212,377.0 212,277.0 797.0,277.0 797.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M797.0,379.0 L801.0,371.0 793.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-5\" stroke-width=\"2px\" d=\"M212,377.0 212,252.0 950.0,252.0 950.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,379.0 L954.0,371.0 946.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-6\" stroke-width=\"2px\" d=\"M1112,377.0 1112,327.0 1391.0,327.0 1391.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1112,379.0 L1108,371.0 1116,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-7\" stroke-width=\"2px\" d=\"M1262,377.0 1262,352.0 1388.0,352.0 1388.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1262,379.0 L1258,371.0 1266,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-8\" stroke-width=\"2px\" d=\"M962,377.0 962,302.0 1394.0,302.0 1394.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a9d3c4a6ba254fcf8ce0ffeb4ff2efc8-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1394.0,379.0 L1398.0,371.0 1390.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'compact': True, 'bg': '#09a3d5', 'color': 'white', 'font': 'Trebuchet MS'}\n",
    "\n",
    "spacy.displacy.render(list(spacy_doc.sents)[0], jupyter=True, style='dep', options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Notation\n",
    "\n",
    "Spacy also provides vector notation of every token which can be used in machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.8092232e+00, -7.9949045e-01, -2.7830656e+00, -3.0911517e+00,\n",
       "       -1.1674500e+00, -1.4541893e+00,  5.8673698e-01,  3.7015960e+00,\n",
       "       -1.6760986e+00,  9.6453130e-03, -7.6414114e-01,  2.3812797e+00,\n",
       "       -5.1507168e+00, -2.0459871e+00,  1.1402875e+00, -1.8937337e+00,\n",
       "        2.8011463e+00,  2.1473169e+00,  8.8128579e-01,  2.7916687e+00,\n",
       "       -3.2916703e+00, -1.8719851e+00, -1.7075145e+00,  4.1843662e+00,\n",
       "       -3.5731611e+00,  2.4751692e+00,  9.6787816e-01,  1.0259242e+00,\n",
       "        4.8604941e+00,  5.9378476e+00,  4.4669271e+00, -1.0225811e+00,\n",
       "       -2.3431373e+00, -4.4107902e-01, -2.1280071e-01,  1.1809008e+00,\n",
       "        9.9521077e-01,  6.4941287e-01,  8.3682561e-01, -3.4059775e+00,\n",
       "       -7.8740013e-01,  1.0042728e+00, -3.5658257e+00,  4.1323221e-01,\n",
       "       -5.9301049e-02, -1.6581726e-01, -4.4719849e+00, -1.3257158e-01,\n",
       "       -2.8641741e+00,  2.3265834e+00, -4.4410124e+00,  1.6012321e+00,\n",
       "       -2.4732838e+00, -2.4635377e+00, -2.6837833e+00,  2.1693599e-01,\n",
       "        3.6622872e+00, -6.0779852e-01, -2.6860981e+00,  1.7240920e+00,\n",
       "       -1.8128412e+00,  4.0345674e+00,  4.2721128e+00, -3.2587051e-03,\n",
       "        5.3550363e-02,  8.8709235e-01,  2.6425426e+00, -1.7769699e+00,\n",
       "       -1.4379121e+00, -1.1434916e+00, -5.0491047e+00, -3.8866839e+00,\n",
       "       -9.9680281e-01,  4.1964383e+00, -1.7295837e-02, -1.1558205e-01,\n",
       "       -4.4583538e-01, -4.4857681e-02, -1.0936908e+00, -3.4832251e+00,\n",
       "       -1.7569822e+00,  2.7481508e+00, -7.9972434e+00,  3.5041434e-01,\n",
       "       -4.1323042e-01,  1.2341330e+00,  1.6193911e+00,  1.2387648e+00,\n",
       "        5.5510664e+00, -1.7126346e+00,  2.9228888e+00,  3.1854780e+00,\n",
       "        5.2858305e-01,  3.3000031e+00, -3.0174196e-01,  5.5732045e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nlp(u'King') # We can take any word like Praveen, Kumar etc.\n",
    "token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.744825  ,  0.62399197, -1.4038447 , -3.6159914 , -3.1707869 ,\n",
       "       -0.536033  , -2.0956917 , -1.0234548 , -2.6209934 ,  1.5763633 ,\n",
       "       -0.4331112 , -0.49205512, -3.3718448 , -4.5636964 ,  0.7077944 ,\n",
       "        0.4111069 ,  2.7638633 ,  6.2883024 ,  0.22936256,  4.982456  ,\n",
       "        0.4428508 , -0.5936458 ,  1.3176374 ,  1.1965301 ,  0.47570387,\n",
       "        1.8369817 , -1.6679952 ,  2.4737792 ,  0.67596805,  7.000798  ,\n",
       "        0.6858903 , -1.6222191 , -1.9003875 , -0.31677732, -0.3156247 ,\n",
       "        4.389676  ,  1.4550285 , -0.5815604 ,  0.6794747 , -2.5833135 ,\n",
       "       -3.0749898 ,  2.3777478 ,  1.2009223 ,  0.9474251 ,  0.76319766,\n",
       "        1.8404324 , -1.0794019 , -1.8069282 , -4.911121  , -0.43919897,\n",
       "       -4.8656993 ,  0.6057688 , -0.39059675, -4.8189144 , -0.92137146,\n",
       "       -3.3053021 ,  1.2637006 , -0.19674015, -2.402514  ,  2.2881408 ,\n",
       "        1.4853647 ,  2.1177125 ,  3.0061064 ,  0.69979787, -0.9318255 ,\n",
       "        1.2034956 ,  1.2796631 ,  3.044861  ,  1.7574408 ,  4.615644  ,\n",
       "       -1.7766149 ,  2.033947  , -1.6789904 , -1.0281274 ,  1.6759723 ,\n",
       "       -1.2545352 , -2.8333097 ,  1.0105354 , -1.7783791 , -1.126149  ,\n",
       "       -2.9084504 ,  2.6594167 , -2.6839983 , -2.3413692 ,  0.30735016,\n",
       "       -1.8037328 ,  1.3585019 ,  0.06524253,  6.6647835 , -2.9869323 ,\n",
       "       -0.76042366,  1.1179767 , -1.1239386 , -2.8042386 , -2.8484676 ,\n",
       "        6.000574  ], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = nlp(u'man')\n",
    "token2.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the similarity between the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chalampp\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5621187787786361"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.similarity(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
