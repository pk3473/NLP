{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from tqdm import tqdm # it is handly library which provide percentage progress bar while executing for loops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_hdf('auto_tagging_data_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions['Text'] = df_questions['Title'] + \" \" + df_questions['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = re.sub(r'<.*?>', '', text) # this removes html tags and url links in the text\n",
    "    \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) # this will remove everything except alphabets\n",
    "    \n",
    "    text = ' '.join(text.split()) # # this will remove extra or white spaces in the text\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions['Text'] = df_questions['Text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions['Text'] = df_questions['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46536</td>\n",
       "      <td>11315</td>\n",
       "      <td>how does the distribution of the error term affect the distribution of the response so when i assume that the error terms are normally distributed in a linear regression what does it mean for the ...</td>\n",
       "      <td>[regression, distributions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25706</td>\n",
       "      <td>48063</td>\n",
       "      <td>distribution expected length of the shortest path in infinite random geometric graphs consider an infinite random geometric graph g rho d in which vertices are uniformly and independently scattere...</td>\n",
       "      <td>[probability, stochastic-processes, pdf]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50808</td>\n",
       "      <td>105171</td>\n",
       "      <td>confidence intervals for predictors in multivariate logistic regression i ve got a question i am dealing with medical data which contain predictors and binary outcome when i try to classify the da...</td>\n",
       "      <td>[regression, logistic, confidence-interval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33445</td>\n",
       "      <td>152369</td>\n",
       "      <td>does rank of observation matrix tell anything useful when applying machine learning suppose i have an observation matrix of size n times m where n is the number of samples and m is the number of v...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39207</td>\n",
       "      <td>141400</td>\n",
       "      <td>how many people initially had apples story problem assume apples are distributed across x unknown people where each person has at least one apple for each apple a biased coin is flipped to see if ...</td>\n",
       "      <td>[estimation, sampling, nonparametric]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  \\\n",
       "46536   11315   \n",
       "25706   48063   \n",
       "50808  105171   \n",
       "33445  152369   \n",
       "39207  141400   \n",
       "\n",
       "                                                                                                                                                                                                          Text  \\\n",
       "46536  how does the distribution of the error term affect the distribution of the response so when i assume that the error terms are normally distributed in a linear regression what does it mean for the ...   \n",
       "25706  distribution expected length of the shortest path in infinite random geometric graphs consider an infinite random geometric graph g rho d in which vertices are uniformly and independently scattere...   \n",
       "50808  confidence intervals for predictors in multivariate logistic regression i ve got a question i am dealing with medical data which contain predictors and binary outcome when i try to classify the da...   \n",
       "33445  does rank of observation matrix tell anything useful when applying machine learning suppose i have an observation matrix of size n times m where n is the number of samples and m is the number of v...   \n",
       "39207  how many people initially had apples story problem assume apples are distributed across x unknown people where each person has at least one apple for each apple a biased coin is flipped to see if ...   \n",
       "\n",
       "                                              Tags  \n",
       "46536                  [regression, distributions]  \n",
       "25706     [probability, stochastic-processes, pdf]  \n",
       "50808  [regression, logistic, confidence-interval]  \n",
       "33445                           [machine-learning]  \n",
       "39207        [estimation, sampling, nonparametric]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions[['Id','Text','Tags']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Text to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Without running in the beginning, writing at the later stage is throwing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_questions['Text']) # It tokenizes the text as well as keeps the index of the resultant tokens\n",
    "\n",
    "                                             # This is really useful as it helps in accessing the words easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81956"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique words count\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the text into sequence of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_questions['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the two cultures statistics vs machine learning last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to this simon blomberg from r s fortunes package to paraphrase provocatively machine learning is statistics minus any checking of models and assumptions brian d ripley about the difference between machine learning and statistics user vienna may season s greetings andrew gelman in that case maybe we should get rid of checking of models and assumptions more often then maybe we d be able to solve some of the problems that the machine learning people can solve but we can t there was also the statistical modeling the two cultures paper by leo breiman in which argued that statisticians rely too heavily on data modeling and that machine learning techniques are making progress by instead relying on the predictive accuracy of models has the statistics field changed over the last decade in response to these critiques do the two cultures still exist or has statistics grown to embrace machine learning techniques such as neural networks and support vector machines \n",
      "\n",
      "[1, 59, 9730, 255, 315, 482, 256, 577, 277, 2, 333, 3, 2733, 374, 36, 24159, 665, 20232, 9413, 255, 315, 482, 256, 12412, 11, 2734, 60, 5, 1, 441, 74, 1, 59, 2265, 3603, 3384, 5009, 18773, 4, 12, 6933, 50267, 36, 45, 34, 38034, 250, 4, 14051, 50268, 482, 256, 6, 255, 2548, 68, 1771, 5, 132, 7, 691, 9140, 70, 9568, 89, 1, 167, 74, 482, 256, 7, 255, 600, 21877, 264, 1580, 34, 10105, 3603, 3384, 8, 11, 143, 580, 54, 83, 103, 3655, 5, 1771, 5, 132, 7, 691, 92, 726, 81, 580, 54, 70, 19, 375, 4, 588, 60, 5, 1, 597, 11, 1, 482, 256, 320, 28, 588, 31, 54, 28, 17, 43, 97, 105, 1, 235, 772, 1, 59, 9730, 433, 55, 16689, 7210, 8, 47, 6113, 11, 3184, 3258, 427, 3024, 21, 13, 772, 7, 11, 482, 256, 865, 18, 912, 3570, 55, 424, 6334, 21, 1, 785, 406, 5, 132, 100, 1, 255, 1056, 1670, 186, 1, 577, 8085, 8, 234, 4, 94, 15913, 48, 1, 59, 9730, 330, 1223, 33, 100, 255, 6392, 4, 16690, 482, 256, 865, 164, 25, 478, 886, 7, 855, 270, 2100]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us see few sample sentences and their corresponding sequence integers\n",
    "\n",
    "i = 0 # index\n",
    "print(df_questions['Text'][i], '\\n'), print(sequences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the meaning of p values and t values in statistical tests after taking a statistics course and then trying to help fellow students i noticed one subject that inspires much head desk banging is interpreting the results of statistical hypothesis tests it seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the results many computerized tools report test results in terms of p values or t values how would you explain the following points to college students taking their first course in statistics what does a p value mean in relation to the hypothesis being tested are there cases when one should be looking for a high p value or a low p value what is the relationship between a p value and a t value \n",
      "\n",
      "[39, 6, 1, 995, 5, 32, 71, 7, 17, 71, 8, 235, 267, 209, 671, 3, 255, 555, 7, 81, 158, 4, 162, 8771, 863, 2, 1786, 50, 302, 11, 31537, 237, 1114, 12413, 15216, 6, 1182, 1, 133, 5, 235, 260, 267, 16, 218, 11, 863, 1209, 692, 30, 4, 387, 1, 1609, 1060, 55, 3, 127, 42, 31, 103, 12777, 195, 21, 1182, 1, 133, 221, 16691, 1746, 814, 42, 133, 8, 339, 5, 32, 71, 33, 17, 71, 30, 41, 69, 448, 1, 135, 190, 4, 2738, 863, 671, 229, 130, 555, 8, 255, 39, 98, 3, 32, 66, 67, 8, 1126, 4, 1, 260, 303, 1119, 18, 43, 405, 76, 50, 83, 19, 248, 9, 3, 313, 32, 66, 33, 3, 429, 32, 66, 39, 6, 1, 456, 74, 3, 32, 66, 7, 3, 17, 66]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3 # index\n",
    "print(df_questions['Text'][i], '\\n'), print(sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the integers corresponding to the text of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding : Making sequences of same length\n",
    "\n",
    "# The model will accept the inputs of the same size i.e. the integer sequences derive from text need to be of same size or length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the distribution of sequences\n",
    "\n",
    "# Finding right maximum length for the sequences\n",
    "\n",
    "seq_lengths = []\n",
    "\n",
    "for i in sequences:\n",
    "    seq_lengths.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th percentile:  97.0\n",
      "40th percentile:  116.0\n",
      "50th percentile:  137.0\n",
      "60th percentile:  162.0\n",
      "70th percentile:  193.0\n",
      "80th percentile:  238.0\n",
      "90th percentile:  320.0\n",
      "95th percentile:  411.0\n",
      "99th percentile:  678.0\n"
     ]
    }
   ],
   "source": [
    "print(\"30th percentile: \", pd.Series(seq_lengths).quantile(0.3))\n",
    "print(\"40th percentile: \", pd.Series(seq_lengths).quantile(0.4))\n",
    "print(\"50th percentile: \", pd.Series(seq_lengths).quantile(0.5))\n",
    "print(\"60th percentile: \", pd.Series(seq_lengths).quantile(0.6))\n",
    "print(\"70th percentile: \", pd.Series(seq_lengths).quantile(0.7))\n",
    "print(\"80th percentile: \", pd.Series(seq_lengths).quantile(0.8))\n",
    "print(\"90th percentile: \", pd.Series(seq_lengths).quantile(0.9))\n",
    "print(\"95th percentile: \", pd.Series(seq_lengths).quantile(0.95))\n",
    "print(\"99th percentile: \", pd.Series(seq_lengths).quantile(0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of the sequences at 50th percentile are less than 124 and half of them are larger than it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study well --> Bit confusing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max_length is a hyper parameter. Having less number leads to loss of information and takes less time to train the model. Higher value for the max length leads to less loss of information and time confusing due to padding with zeros. Hence it is a hyper paramter to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 125\n",
    "\n",
    "# padding\n",
    "padded_seq = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions['Tags'])\n",
    "y = multilabel_binarizer.transform(df_questions['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76365, 125), (76365, 100))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(padded_seq, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Sequential - Model Building\n",
    "# load_model - laading and save model to memory\n",
    "# Earlystoppin & ModelCheckpoint - To save time while training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Spam-Ham classification, we have used functional API of Keras here we are going to use Sequential API to buid the multilabel classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "# this layer is useful to create word vectors. This job is similar to word2vec or Glove\n",
    "# len(tokenizer.word_index)+1 ==> size of the vocabulary\n",
    "# the additional 1 is for the integer we get by the zeros used for padding\n",
    "# 128 ==> size of the embedding which means the size of the word vectors\n",
    "\n",
    "model.add(Embedding(len(tokenizer.word_index)+1, 128, input_length = max_length)) \n",
    "\n",
    "model.add(Dropout(0.15)) #15% dropping out which helps in reducing overfitting \n",
    "\n",
    "model.add(Conv1D(300, 3, padding = 'valid', activation = \"relu\", strides = 1)) #\n",
    "\n",
    "model.add(GlobalMaxPool1D()) # This extracts valuable features from sequences\n",
    "\n",
    "model.add(Dense(100, activation = \"sigmoid\")) # Since we need to predict the probabilities, we are using sigmoid\n",
    "\n",
    "#model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 125, 128)          10490496  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 123, 300)          115500    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               30100     \n",
      "=================================================================\n",
      "Total params: 10,636,096\n",
      "Trainable params: 10,636,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see 1 million trainable parameters(10,636,096). More number of Parameters takes more time to train the model, since Deep Learning model takes more time train as compare to ML Models it is advisable to use the features like early stopping and saving the best model for later use. We can use this features using callbacks from keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "             EarlyStopping(patience=3), # It will wait for 3 epochs, even after 3 ephocs performance doesn't then training of the model will stop\n",
    "             ModelCheckpoint(filepath='model-conv1d_v1.h5', save_best_only=True)\n",
    "            ]   # our best model will be saved with the name 'model-conv1d_v1.h5' in our working directory\n",
    "\n",
    "                # save_best_only = True, it saves best model on performance using validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BADE4C78B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001BADE4C78B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/108 [..............................] - ETA: 0s - loss: 0.6934 - accuracy: 0.0020"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Performane Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the code below to load the saved model. It appears similar to pickle\n",
    "# model = load_model('model-conv1d_v1.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_val) # These predictions are probabilities. Therefor we will be converting to binary using threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold to 0.45\n",
    "\n",
    "# we can also try different values\n",
    "\n",
    "preds_int = (preds >= 0.45).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 score\n",
    "f1_score(y_val, preds_int, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1score() of 0.510 is observer which is good improvement...We can keep increase the number of epochs as long as the validation loss continues to decline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try changing the architecture of the model (add more convolutional layers, play around with number of units in each layer, change the value of dropout etc). We can also try completely different architectures such as RNN/LSTM..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model-conv1d_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    q = clean_text(q)\n",
    "    q = q.lower()\n",
    "    q_seq = tokenizer.texts_to_sequences([q])\n",
    "    q_seq_padded = pad_sequences(q_seq, maxlen=300)\n",
    "    q_pred = model.predict(q_seq_padded)\n",
    "    q_pred = (q_pred >= 0.3).astype(int)\n",
    "    \n",
    "    return multilabel_binarizer.inverse_transform(q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give new question\n",
    "new_q = \"Regression line in ggplot doesn't match computed regression Im using R and created a chart using ggplot2. I then create a regression so I can make some predicitions I pass my data frame of to the predict function predict(regression, Measures) I'd expect the predictions to be the same as if I used the regression line on the chart, but they aren't the same. Why would this be the case? Is there a setting in ggplot or is my expectation incorrect?\"\n",
    "\n",
    "# get tags\n",
    "infer_tags(new_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
